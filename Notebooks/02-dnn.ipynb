{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909ee9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:01.306059Z",
     "iopub.status.busy": "2025-06-20T07:05:01.305749Z",
     "iopub.status.idle": "2025-06-20T07:05:05.512286Z",
     "shell.execute_reply": "2025-06-20T07:05:05.511371Z"
    },
    "papermill": {
     "duration": 4.215623,
     "end_time": "2025-06-20T07:05:05.514190",
     "exception": false,
     "start_time": "2025-06-20T07:05:01.298567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4629771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:05.526666Z",
     "iopub.status.busy": "2025-06-20T07:05:05.525902Z",
     "iopub.status.idle": "2025-06-20T07:05:05.619434Z",
     "shell.execute_reply": "2025-06-20T07:05:05.618408Z"
    },
    "papermill": {
     "duration": 0.101541,
     "end_time": "2025-06-20T07:05:05.621280",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.519739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X_train = pd.read_csv('/kaggle/input/qcd-tt-jet-tagging-hsf-india-bangalore/train/features/cluster_features.csv')\n",
    "y_train = np.load('/kaggle/input/qcd-tt-jet-tagging-hsf-india-bangalore/train/labels/labels.npy')\n",
    "\n",
    "# Load validation data\n",
    "X_val = pd.read_csv('/kaggle/input/qcd-tt-jet-tagging-hsf-india-bangalore/val/features/cluster_features.csv')\n",
    "y_val = np.load('/kaggle/input/qcd-tt-jet-tagging-hsf-india-bangalore/val/labels/labels.npy')\n",
    "\n",
    "# Load test data (no labels)\n",
    "X_test = pd.read_csv('/kaggle/input/qcd-tt-jet-tagging-hsf-india-bangalore/test/features/cluster_features.csv')\n",
    "test_ids = np.load('/kaggle/input/qcd-tt-jet-tagging-hsf-india-bangalore/test/ids/ids.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bfab10",
   "metadata": {
    "papermill": {
     "duration": 0.00478,
     "end_time": "2025-06-20T07:05:05.631566",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.626786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DEEP NEURAL NETWORK (DNN) - STANDARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e81016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:05.643013Z",
     "iopub.status.busy": "2025-06-20T07:05:05.642330Z",
     "iopub.status.idle": "2025-06-20T07:05:05.860694Z",
     "shell.execute_reply": "2025-06-20T07:05:05.859733Z"
    },
    "papermill": {
     "duration": 0.225833,
     "end_time": "2025-06-20T07:05:05.862423",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.636590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7021a5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:05.874534Z",
     "iopub.status.busy": "2025-06-20T07:05:05.874208Z",
     "iopub.status.idle": "2025-06-20T07:05:05.881357Z",
     "shell.execute_reply": "2025-06-20T07:05:05.880516Z"
    },
    "papermill": {
     "duration": 0.015298,
     "end_time": "2025-06-20T07:05:05.882910",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.867612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n# Build DNN\\ndnn = Sequential([\\n    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\\n    Dropout(0.3),\\n    Dense(64, activation='relu'),\\n    Dropout(0.3),\\n    Dense(32, activation='relu'),\\n    Dense(1, activation='sigmoid')  # Binary output\\n])\\n\\n# Compile\\ndnn.compile(\\n    optimizer='adam',\\n    loss='binary_crossentropy',\\n    metrics=['AUC']\\n)\\n\\n# Callbacks\\nearly_stop = EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\\n\\n# Train\\nhistory = dnn.fit(\\n    X_train_scaled, y_train,\\n    validation_data=(X_val_scaled, y_val),\\n    epochs=100,\\n    batch_size=128,\\n    callbacks=[early_stop],\\n    verbose=1\\n)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Build DNN\n",
    "dnn = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary output\n",
    "])\n",
    "\n",
    "# Compile\n",
    "dnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['AUC']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "\n",
    "# Train\n",
    "history = dnn.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2bb7ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:05.894583Z",
     "iopub.status.busy": "2025-06-20T07:05:05.894205Z",
     "iopub.status.idle": "2025-06-20T07:05:05.900330Z",
     "shell.execute_reply": "2025-06-20T07:05:05.899226Z"
    },
    "papermill": {
     "duration": 0.013546,
     "end_time": "2025-06-20T07:05:05.901814",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.888268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Plot training and validation AUC\\nplt.figure(figsize=(8, 5))\\nplt.plot(history.history['AUC'], label='Train AUC')\\nplt.plot(history.history['val_AUC'], label='Validation AUC')\\nplt.title('Training vs Validation AUC Over Epochs')\\nplt.xlabel('Epoch')\\nplt.ylabel('AUC')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Plot training and validation AUC\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['AUC'], label='Train AUC')\n",
    "plt.plot(history.history['val_AUC'], label='Validation AUC')\n",
    "plt.title('Training vs Validation AUC Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742c258b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:05.913842Z",
     "iopub.status.busy": "2025-06-20T07:05:05.913505Z",
     "iopub.status.idle": "2025-06-20T07:05:05.919634Z",
     "shell.execute_reply": "2025-06-20T07:05:05.918751Z"
    },
    "papermill": {
     "duration": 0.0139,
     "end_time": "2025-06-20T07:05:05.921148",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.907248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.metrics import roc_auc_score, roc_curve\\nimport matplotlib.pyplot as plt\\n\\n# Predict probabilities on validation set\\nval_preds_dnn = dnn.predict(X_val_scaled).flatten()\\n\\n# Compute ROC AUC\\nauc_dnn = roc_auc_score(y_val, val_preds_dnn)\\nprint(f\"âœ… Best Model: DNN | Validation AUC: {auc_dnn:.4f}\")\\n\\n# Compute ROC curve\\nfpr, tpr, _ = roc_curve(y_val, val_preds_dnn)\\n\\n# Plot ROC\\nplt.figure(figsize=(8, 6))\\nplt.plot(fpr, tpr, label=f\\'DNN (AUC = {auc_dnn:.4f})\\', color=\\'darkorange\\')\\nplt.plot([0, 1], [0, 1], linestyle=\\'--\\', color=\\'gray\\')\\nplt.xlabel(\"False Positive Rate\")\\nplt.ylabel(\"True Positive Rate\")\\nplt.title(\"ROC Curve â€“ Best Model (DNN)\")\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict probabilities on validation set\n",
    "val_preds_dnn = dnn.predict(X_val_scaled).flatten()\n",
    "\n",
    "# Compute ROC AUC\n",
    "auc_dnn = roc_auc_score(y_val, val_preds_dnn)\n",
    "print(f\"âœ… Best Model: DNN | Validation AUC: {auc_dnn:.4f}\")\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_val, val_preds_dnn)\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'DNN (AUC = {auc_dnn:.4f})', color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve â€“ Best Model (DNN)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74861d30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:05.933615Z",
     "iopub.status.busy": "2025-06-20T07:05:05.933258Z",
     "iopub.status.idle": "2025-06-20T07:05:05.939025Z",
     "shell.execute_reply": "2025-06-20T07:05:05.938168Z"
    },
    "papermill": {
     "duration": 0.013775,
     "end_time": "2025-06-20T07:05:05.940436",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.926661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnp.save('/kaggle/working/03_dnn_preds.npy', val_preds_dnn)\\n\\n# Scale test data using the same StandardScaler\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Predict on scaled test data\\ntest_dnn_preds = dnn.predict(X_test_scaled, batch_size=512).flatten()\\nnp.save('/kaggle/working/03_dnn_test_preds.npy', test_dnn_preds)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "np.save('/kaggle/working/03_dnn_preds.npy', val_preds_dnn)\n",
    "\n",
    "# Scale test data using the same StandardScaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict on scaled test data\n",
    "test_dnn_preds = dnn.predict(X_test_scaled, batch_size=512).flatten()\n",
    "np.save('/kaggle/working/03_dnn_test_preds.npy', test_dnn_preds)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37116c4d",
   "metadata": {
    "papermill": {
     "duration": 0.005222,
     "end_time": "2025-06-20T07:05:05.951138",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.945916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Standard DNN - Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4d0227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:05.964287Z",
     "iopub.status.busy": "2025-06-20T07:05:05.963336Z",
     "iopub.status.idle": "2025-06-20T07:05:05.969792Z",
     "shell.execute_reply": "2025-06-20T07:05:05.969078Z"
    },
    "papermill": {
     "duration": 0.014613,
     "end_time": "2025-06-20T07:05:05.971436",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.956823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load test IDs and DNN test predictions\\ntest_ids = np.load(\\'/kaggle/input/qcd-tt-jet-tagging-hsf-india-bangalore/test/ids/ids.npy\\')\\ntest_preds_dnn = np.load(\\'/kaggle/working/03_dnn_test_preds.npy\\')\\n\\n# Create submission DataFrame\\nsubmission_dnn = pd.DataFrame({\\n    \\'id\\': test_ids,\\n    \\'label\\': test_preds_dnn\\n})\\n\\n# Save to CSV\\nsubmission_dnn.to_csv(\\'/kaggle/working/submission.csv\\', index=False)\\nprint(\"DNN submission file saved: submission.csv\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Load test IDs and DNN test predictions\n",
    "test_ids = np.load('/kaggle/input/qcd-tt-jet-tagging-hsf-india-bangalore/test/ids/ids.npy')\n",
    "test_preds_dnn = np.load('/kaggle/working/03_dnn_test_preds.npy')\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_dnn = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': test_preds_dnn\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_dnn.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"DNN submission file saved: submission.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b50fbc",
   "metadata": {
    "papermill": {
     "duration": 0.005175,
     "end_time": "2025-06-20T07:05:05.982133",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.976958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9552da51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:05.994594Z",
     "iopub.status.busy": "2025-06-20T07:05:05.994261Z",
     "iopub.status.idle": "2025-06-20T07:05:06.031275Z",
     "shell.execute_reply": "2025-06-20T07:05:06.030370Z"
    },
    "papermill": {
     "duration": 0.045183,
     "end_time": "2025-06-20T07:05:06.032839",
     "exception": false,
     "start_time": "2025-06-20T07:05:05.987656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: Feature engineering and scaling applied\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Copying for Feature Engineering\n",
    "\n",
    "X_train_fe = X_train.copy()\n",
    "X_val_fe = X_val.copy()\n",
    "X_test_fe = X_test.copy()\n",
    "\n",
    "# 1. Log transform of total_pt â€” reduces skew and handles large scale\n",
    "X_train_fe['log_total_pt'] = np.log1p(X_train_fe['total_pt'])\n",
    "X_val_fe['log_total_pt'] = np.log1p(X_val_fe['total_pt'])\n",
    "X_test_fe['log_total_pt'] = np.log1p(X_test_fe['total_pt'])\n",
    "\n",
    "# 2. pt per cluster â€” normalizes energy by cluster count\n",
    "X_train_fe['pt_per_cluster'] = X_train_fe['total_pt'] / (X_train_fe['n_clusters'] + 1e-5)\n",
    "X_val_fe['pt_per_cluster'] = X_val_fe['total_pt'] / (X_val_fe['n_clusters'] + 1e-5)\n",
    "X_test_fe['pt_per_cluster'] = X_test_fe['total_pt'] / (X_test_fe['n_clusters'] + 1e-5)\n",
    "\n",
    "# 3. pt to cluster size ratio â€” captures energy concentration\n",
    "X_train_fe['pt_size_ratio'] = X_train_fe['mean_cluster_pt'] / (X_train_fe['mean_cluster_size'] + 1e-5)\n",
    "X_val_fe['pt_size_ratio'] = X_val_fe['mean_cluster_pt'] / (X_val_fe['mean_cluster_size'] + 1e-5)\n",
    "X_test_fe['pt_size_ratio'] = X_test_fe['mean_cluster_pt'] / (X_test_fe['mean_cluster_size'] + 1e-5)\n",
    "\n",
    "# 4. Eta-phi spread â€” measures spatial dispersion\n",
    "X_train_fe['eta_phi_spread'] = (X_train_fe['max_cluster_eta'] - X_train_fe['mean_cluster_eta']) * \\\n",
    "                               (X_train_fe['max_cluster_phi'] - X_train_fe['mean_cluster_phi'])\n",
    "X_val_fe['eta_phi_spread'] = (X_val_fe['max_cluster_eta'] - X_val_fe['mean_cluster_eta']) * \\\n",
    "                             (X_val_fe['max_cluster_phi'] - X_val_fe['mean_cluster_phi'])\n",
    "X_test_fe['eta_phi_spread'] = (X_test_fe['max_cluster_eta'] - X_test_fe['mean_cluster_eta']) * \\\n",
    "                              (X_test_fe['max_cluster_phi'] - X_test_fe['mean_cluster_phi'])\n",
    "\n",
    "# --------------------------------------------\n",
    "# âœ³ï¸ Standard Scaling for DNN\n",
    "# --------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_fe)\n",
    "X_val_scaled = scaler.transform(X_val_fe)\n",
    "X_test_scaled = scaler.transform(X_test_fe)\n",
    "\n",
    "print(\"Done: Feature engineering and scaling applied\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7cd29",
   "metadata": {
    "papermill": {
     "duration": 0.005547,
     "end_time": "2025-06-20T07:05:06.044218",
     "exception": false,
     "start_time": "2025-06-20T07:05:06.038671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DNN - After Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9eaefc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:06.057489Z",
     "iopub.status.busy": "2025-06-20T07:05:06.056813Z",
     "iopub.status.idle": "2025-06-20T07:05:06.063539Z",
     "shell.execute_reply": "2025-06-20T07:05:06.062386Z"
    },
    "papermill": {
     "duration": 0.014746,
     "end_time": "2025-06-20T07:05:06.065118",
     "exception": false,
     "start_time": "2025-06-20T07:05:06.050372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n# Build a deeper and more regularized DNN\\ndnn = Sequential([\\n    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\\n    BatchNormalization(),\\n    Dropout(0.3),\\n\\n    Dense(64, activation='relu'),\\n    BatchNormalization(),\\n    Dropout(0.3),\\n\\n    Dense(32, activation='relu'),\\n    Dense(1, activation='sigmoid')  # Binary classification\\n])\\n\\n# Compile with AUC as the key metric\\ndnn.compile(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n    loss='binary_crossentropy',\\n    metrics=[tf.keras.metrics.AUC(name='AUC')]\\n)\\n\\n# Early stopping to avoid overfitting\\nearly_stop = EarlyStopping(\\n    monitor='val_AUC', patience=10, restore_best_weights=True, mode='max'\\n)\\n\\n# Train the model\\nhistory = dnn.fit(\\n    X_train_scaled, y_train,\\n    validation_data=(X_val_scaled, y_val),\\n    epochs=100,\\n    batch_size=128,\\n    callbacks=[early_stop],\\n    verbose=1\\n)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Build a deeper and more regularized DNN\n",
    "dnn = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile with AUC as the key metric\n",
    "dnn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.AUC(name='AUC')]\n",
    ")\n",
    "\n",
    "# Early stopping to avoid overfitting\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_AUC', patience=10, restore_best_weights=True, mode='max'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = dnn.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed98d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:06.078592Z",
     "iopub.status.busy": "2025-06-20T07:05:06.077983Z",
     "iopub.status.idle": "2025-06-20T07:05:06.084234Z",
     "shell.execute_reply": "2025-06-20T07:05:06.083196Z"
    },
    "papermill": {
     "duration": 0.014928,
     "end_time": "2025-06-20T07:05:06.085926",
     "exception": false,
     "start_time": "2025-06-20T07:05:06.070998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(8, 5))\\nplt.plot(history.history['AUC'], label='Train AUC')\\nplt.plot(history.history['val_AUC'], label='Validation AUC')\\nplt.title('Training vs Validation AUC Over Epochs')\\nplt.xlabel('Epoch')\\nplt.ylabel('AUC')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['AUC'], label='Train AUC')\n",
    "plt.plot(history.history['val_AUC'], label='Validation AUC')\n",
    "plt.title('Training vs Validation AUC Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a97bbd53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:06.099201Z",
     "iopub.status.busy": "2025-06-20T07:05:06.098840Z",
     "iopub.status.idle": "2025-06-20T07:05:06.104769Z",
     "shell.execute_reply": "2025-06-20T07:05:06.103833Z"
    },
    "papermill": {
     "duration": 0.014315,
     "end_time": "2025-06-20T07:05:06.106233",
     "exception": false,
     "start_time": "2025-06-20T07:05:06.091918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.metrics import roc_auc_score, roc_curve\\n\\n# Validation predictions\\nval_preds_dnn = dnn.predict(X_val_scaled).flatten()\\nval_auc_dnn = roc_auc_score(y_val, val_preds_dnn)\\nprint(f\"âœ… Final Validation AUC (DNN): {val_auc_dnn:.5f}\")\\n\\n# Test predictions\\ntest_preds_dnn = dnn.predict(X_test_scaled, batch_size=512).flatten()\\n\\n# Save .npy if needed\\nnp.save(\\'/kaggle/working/002dnn_val_preds.npy\\', val_preds_dnn)\\nnp.save(\\'/kaggle/working/002dnn_test_preds.npy\\', test_preds_dnn)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Validation predictions\n",
    "val_preds_dnn = dnn.predict(X_val_scaled).flatten()\n",
    "val_auc_dnn = roc_auc_score(y_val, val_preds_dnn)\n",
    "print(f\"âœ… Final Validation AUC (DNN): {val_auc_dnn:.5f}\")\n",
    "\n",
    "# Test predictions\n",
    "test_preds_dnn = dnn.predict(X_test_scaled, batch_size=512).flatten()\n",
    "\n",
    "# Save .npy if needed\n",
    "np.save('/kaggle/working/002dnn_val_preds.npy', val_preds_dnn)\n",
    "np.save('/kaggle/working/002dnn_test_preds.npy', test_preds_dnn)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9413b72a",
   "metadata": {
    "papermill": {
     "duration": 0.005677,
     "end_time": "2025-06-20T07:05:06.118092",
     "exception": false,
     "start_time": "2025-06-20T07:05:06.112415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DNN with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0982f3ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:06.131585Z",
     "iopub.status.busy": "2025-06-20T07:05:06.131262Z",
     "iopub.status.idle": "2025-06-20T07:05:06.138869Z",
     "shell.execute_reply": "2025-06-20T07:05:06.138015Z"
    },
    "papermill": {
     "duration": 0.016281,
     "end_time": "2025-06-20T07:05:06.140348",
     "exception": false,
     "start_time": "2025-06-20T07:05:06.124067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport tensorflow as tf\\nfrom sklearn.model_selection import KFold\\nfrom sklearn.metrics import roc_auc_score\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n# Define a function to build the model with parameters\\ndef build_model(input_dim, units=128, dropout=0.3, learning_rate=0.001):\\n    model = Sequential([\\n        Dense(units, activation=\\'relu\\', input_shape=(input_dim,)),\\n        BatchNormalization(),\\n        Dropout(dropout),\\n        Dense(units//2, activation=\\'relu\\'),\\n        BatchNormalization(),\\n        Dropout(dropout),\\n        Dense(1, activation=\\'sigmoid\\')\\n    ])\\n    model.compile(\\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\\n        loss=\\'binary_crossentropy\\',\\n        metrics=[tf.keras.metrics.AUC(name=\\'AUC\\')]\\n    )\\n    return model\\n\\n# Define hyperparameter grid\\nparam_grid = [\\n    {\\'units\\': 128, \\'dropout\\': 0.3, \\'learning_rate\\': 0.001, \\'batch_size\\': 128},\\n    {\\'units\\': 128, \\'dropout\\': 0.4, \\'learning_rate\\': 0.001, \\'batch_size\\': 128},\\n    {\\'units\\': 128, \\'dropout\\': 0.3, \\'learning_rate\\': 0.0005, \\'batch_size\\': 128},\\n    {\\'units\\': 64,  \\'dropout\\': 0.3, \\'learning_rate\\': 0.001, \\'batch_size\\': 128},\\n    {\\'units\\': 64,  \\'dropout\\': 0.4, \\'learning_rate\\': 0.001, \\'batch_size\\': 128},\\n    {\\'units\\': 128, \\'dropout\\': 0.3, \\'learning_rate\\': 0.001, \\'batch_size\\': 64},\\n    {\\'units\\': 128, \\'dropout\\': 0.4, \\'learning_rate\\': 0.0005, \\'batch_size\\': 64},\\n    {\\'units\\': 64,  \\'dropout\\': 0.3, \\'learning_rate\\': 0.0005, \\'batch_size\\': 64},\\n]\\n\\n# Setup KFold\\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\\nresults = []\\n\\n# Start grid search with cross-validation\\nfor params in param_grid:\\n    print(f\"\\nğŸ” Testing config: {params}\")\\n    fold_aucs = []\\n\\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_scaled)):\\n        X_tr, X_val_cv = X_train_scaled[train_idx], X_train_scaled[val_idx]\\n        y_tr, y_val_cv = y_train[train_idx], y_train[val_idx]\\n\\n        model = build_model(\\n            input_dim=X_tr.shape[1],\\n            units=params[\\'units\\'],\\n            dropout=params[\\'dropout\\'],\\n            learning_rate=params[\\'learning_rate\\']\\n        )\\n\\n        early_stop = EarlyStopping(\\n            monitor=\\'val_AUC\\', patience=10, restore_best_weights=True, mode=\\'max\\'\\n        )\\n\\n        model.fit(\\n            X_tr, y_tr,\\n            validation_data=(X_val_cv, y_val_cv),\\n            epochs=100,\\n            batch_size=params[\\'batch_size\\'],\\n            callbacks=[early_stop],\\n            verbose=0\\n        )\\n\\n        preds = model.predict(X_val_cv, batch_size=512).flatten()\\n        auc = roc_auc_score(y_val_cv, preds)\\n        fold_aucs.append(auc)\\n        print(f\"  Fold {fold+1} AUC: {auc:.5f}\")\\n\\n    avg_auc = np.mean(fold_aucs)\\n    std_auc = np.std(fold_aucs)\\n    results.append({\\n        \\'params\\': params,\\n        \\'avg_auc\\': avg_auc,\\n        \\'std_auc\\': std_auc\\n    })\\n    print(f\"âœ… Avg AUC: {avg_auc:.5f} | Std: {std_auc:.5f}\")\\n\\n# Sort results by highest average AUC\\nsorted_results = sorted(results, key=lambda x: x[\\'avg_auc\\'], reverse=True)\\nbest_result = sorted_results[0]\\n\\nimport pandas as pd\\ndf_cv_results = pd.DataFrame(sorted_results)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define a function to build the model with parameters\n",
    "def build_model(input_dim, units=128, dropout=0.3, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Dense(units, activation='relu', input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout),\n",
    "        Dense(units//2, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.AUC(name='AUC')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = [\n",
    "    {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128},\n",
    "    {'units': 128, 'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128},\n",
    "    {'units': 128, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 128},\n",
    "    {'units': 64,  'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 128},\n",
    "    {'units': 64,  'dropout': 0.4, 'learning_rate': 0.001, 'batch_size': 128},\n",
    "    {'units': 128, 'dropout': 0.3, 'learning_rate': 0.001, 'batch_size': 64},\n",
    "    {'units': 128, 'dropout': 0.4, 'learning_rate': 0.0005, 'batch_size': 64},\n",
    "    {'units': 64,  'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 64},\n",
    "]\n",
    "\n",
    "# Setup KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "# Start grid search with cross-validation\n",
    "for params in param_grid:\n",
    "    print(f\"\\nğŸ” Testing config: {params}\")\n",
    "    fold_aucs = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_scaled)):\n",
    "        X_tr, X_val_cv = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_tr, y_val_cv = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model = build_model(\n",
    "            input_dim=X_tr.shape[1],\n",
    "            units=params['units'],\n",
    "            dropout=params['dropout'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "\n",
    "        early_stop = EarlyStopping(\n",
    "            monitor='val_AUC', patience=10, restore_best_weights=True, mode='max'\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            validation_data=(X_val_cv, y_val_cv),\n",
    "            epochs=100,\n",
    "            batch_size=params['batch_size'],\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_val_cv, batch_size=512).flatten()\n",
    "        auc = roc_auc_score(y_val_cv, preds)\n",
    "        fold_aucs.append(auc)\n",
    "        print(f\"  Fold {fold+1} AUC: {auc:.5f}\")\n",
    "\n",
    "    avg_auc = np.mean(fold_aucs)\n",
    "    std_auc = np.std(fold_aucs)\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'avg_auc': avg_auc,\n",
    "        'std_auc': std_auc\n",
    "    })\n",
    "    print(f\"âœ… Avg AUC: {avg_auc:.5f} | Std: {std_auc:.5f}\")\n",
    "\n",
    "# Sort results by highest average AUC\n",
    "sorted_results = sorted(results, key=lambda x: x['avg_auc'], reverse=True)\n",
    "best_result = sorted_results[0]\n",
    "\n",
    "import pandas as pd\n",
    "df_cv_results = pd.DataFrame(sorted_results)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "038cd25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:06.154626Z",
     "iopub.status.busy": "2025-06-20T07:05:06.153743Z",
     "iopub.status.idle": "2025-06-20T07:05:06.158004Z",
     "shell.execute_reply": "2025-06-20T07:05:06.157107Z"
    },
    "papermill": {
     "duration": 0.012899,
     "end_time": "2025-06-20T07:05:06.159627",
     "exception": false,
     "start_time": "2025-06-20T07:05:06.146728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the results directly\n",
    "#df_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed81ea",
   "metadata": {
    "papermill": {
     "duration": 0.005977,
     "end_time": "2025-06-20T07:05:06.171942",
     "exception": false,
     "start_time": "2025-06-20T07:05:06.165965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DNN - Final Training with best config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3645ec8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:06.186821Z",
     "iopub.status.busy": "2025-06-20T07:05:06.186101Z",
     "iopub.status.idle": "2025-06-20T07:05:33.672544Z",
     "shell.execute_reply": "2025-06-20T07:05:33.671214Z"
    },
    "papermill": {
     "duration": 27.496211,
     "end_time": "2025-06-20T07:05:33.674160",
     "exception": false,
     "start_time": "2025-06-20T07:05:06.177949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 07:05:08.289722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750403108.592498      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750403108.677005      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-06-20 07:05:24.780038: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - AUC: 0.7225 - loss: 0.7190 - val_AUC: 0.9280 - val_loss: 0.4710\n",
      "Epoch 2/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9108 - loss: 0.4216 - val_AUC: 0.9356 - val_loss: 0.4395\n",
      "Epoch 3/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9222 - loss: 0.3695 - val_AUC: 0.9360 - val_loss: 0.4177\n",
      "Epoch 4/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9295 - loss: 0.3421 - val_AUC: 0.9407 - val_loss: 0.3938\n",
      "Epoch 5/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9257 - loss: 0.3404 - val_AUC: 0.9418 - val_loss: 0.3759\n",
      "Epoch 6/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9245 - loss: 0.3356 - val_AUC: 0.9417 - val_loss: 0.3581\n",
      "Epoch 7/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9257 - loss: 0.3334 - val_AUC: 0.9442 - val_loss: 0.3417\n",
      "Epoch 8/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9344 - loss: 0.3061 - val_AUC: 0.9458 - val_loss: 0.3254\n",
      "Epoch 9/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9298 - loss: 0.3221 - val_AUC: 0.9421 - val_loss: 0.3157\n",
      "Epoch 10/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9312 - loss: 0.3149 - val_AUC: 0.9434 - val_loss: 0.2986\n",
      "Epoch 11/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9323 - loss: 0.3173 - val_AUC: 0.9442 - val_loss: 0.2953\n",
      "Epoch 12/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9398 - loss: 0.2951 - val_AUC: 0.9446 - val_loss: 0.2842\n",
      "Epoch 13/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9382 - loss: 0.2978 - val_AUC: 0.9465 - val_loss: 0.2801\n",
      "Epoch 14/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9390 - loss: 0.2977 - val_AUC: 0.9465 - val_loss: 0.2714\n",
      "Epoch 15/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9375 - loss: 0.2942 - val_AUC: 0.9464 - val_loss: 0.2723\n",
      "Epoch 16/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9372 - loss: 0.2979 - val_AUC: 0.9446 - val_loss: 0.2699\n",
      "Epoch 17/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9412 - loss: 0.2862 - val_AUC: 0.9444 - val_loss: 0.2719\n",
      "Epoch 18/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9386 - loss: 0.2880 - val_AUC: 0.9441 - val_loss: 0.2713\n",
      "Epoch 19/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9434 - loss: 0.2827 - val_AUC: 0.9450 - val_loss: 0.2677\n",
      "Epoch 20/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9454 - loss: 0.2792 - val_AUC: 0.9448 - val_loss: 0.2688\n",
      "Epoch 21/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9368 - loss: 0.2966 - val_AUC: 0.9450 - val_loss: 0.2688\n",
      "Epoch 22/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - AUC: 0.9457 - loss: 0.2787 - val_AUC: 0.9461 - val_loss: 0.2641\n",
      "Epoch 23/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - AUC: 0.9319 - loss: 0.3125 - val_AUC: 0.9450 - val_loss: 0.2662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c9b76e3d950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Final model\n",
    "final_dnn = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "final_dnn.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['AUC']\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_AUC', patience=10, restore_best_weights=True, mode='max')\n",
    "\n",
    "# Train on full training data, validate on your validation split\n",
    "final_dnn.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "411edd49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:33.698815Z",
     "iopub.status.busy": "2025-06-20T07:05:33.697877Z",
     "iopub.status.idle": "2025-06-20T07:05:34.219565Z",
     "shell.execute_reply": "2025-06-20T07:05:34.218627Z"
    },
    "papermill": {
     "duration": 0.535258,
     "end_time": "2025-06-20T07:05:34.221188",
     "exception": false,
     "start_time": "2025-06-20T07:05:33.685930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "âœ… Final Model Validation AUC: 0.94637\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step \n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "val_preds = final_dnn.predict(X_val_scaled, batch_size=512).flatten()\n",
    "from sklearn.metrics import roc_auc_score\n",
    "val_auc = roc_auc_score(y_val, val_preds)\n",
    "print(f\"âœ… Final Model Validation AUC: {val_auc:.5f}\")\n",
    "\n",
    "# Predict on test\n",
    "test_preds = final_dnn.predict(X_test_scaled, batch_size=512).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5fc0e80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:34.246249Z",
     "iopub.status.busy": "2025-06-20T07:05:34.245540Z",
     "iopub.status.idle": "2025-06-20T07:05:34.259972Z",
     "shell.execute_reply": "2025-06-20T07:05:34.259065Z"
    },
    "papermill": {
     "duration": 0.028329,
     "end_time": "2025-06-20T07:05:34.261371",
     "exception": false,
     "start_time": "2025-06-20T07:05:34.233042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Submission saved as: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Save submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': test_preds\n",
    "})\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"ğŸš€ Submission saved as: submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8201062f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:34.287531Z",
     "iopub.status.busy": "2025-06-20T07:05:34.286343Z",
     "iopub.status.idle": "2025-06-20T07:05:34.292377Z",
     "shell.execute_reply": "2025-06-20T07:05:34.291518Z"
    },
    "papermill": {
     "duration": 0.020692,
     "end_time": "2025-06-20T07:05:34.293861",
     "exception": false,
     "start_time": "2025-06-20T07:05:34.273169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DNN test predictions as 02_dnn_tuned_test_preds.npy\n"
     ]
    }
   ],
   "source": [
    "# Save as .npy for ensembling\n",
    "np.save('/kaggle/working/02_dnn_tuned_test_preds.npy', test_preds)\n",
    "\n",
    "print(\"Saved DNN test predictions as 02_dnn_tuned_test_preds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d242f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T07:05:34.319119Z",
     "iopub.status.busy": "2025-06-20T07:05:34.318403Z",
     "iopub.status.idle": "2025-06-20T07:05:34.687862Z",
     "shell.execute_reply": "2025-06-20T07:05:34.686796Z"
    },
    "papermill": {
     "duration": 0.383478,
     "end_time": "2025-06-20T07:05:34.689306",
     "exception": false,
     "start_time": "2025-06-20T07:05:34.305828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "âœ… Final DNN Validation AUC: 0.94637\n",
      "ğŸ’¾ Saved DNN validation predictions: dnn_tuned_val_preds.npy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Predict on validation set using final DNN\n",
    "val_preds_dnn = final_dnn.predict(X_val_scaled, batch_size=512).flatten()\n",
    "\n",
    "# Calculate and display AUC\n",
    "val_auc_dnn = roc_auc_score(y_val, val_preds_dnn)\n",
    "print(f\"âœ… Final DNN Validation AUC: {val_auc_dnn:.5f}\")\n",
    "\n",
    "# Save predictions as .npy file for ensembling\n",
    "np.save('/kaggle/working/dnn_tuned_val_preds.npy', val_preds_dnn)\n",
    "\n",
    "print(\"ğŸ’¾ Saved DNN validation predictions: dnn_tuned_val_preds.npy\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12521872,
     "sourceId": 104026,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.240626,
   "end_time": "2025-06-20T07:05:37.387180",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-20T07:04:56.146554",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
